{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m spacy download en_core_web_smData Generation\n",
    "\n",
    "Data was generated in 2 steps:\n",
    "\n",
    "1.Initial Data was captured internally via Google Form which asked users for car issues they currently have or had in the past\n",
    "Classified that data into: brakes, starter, other\n",
    "\n",
    "2.Took this 'training set' and used Markovify to generate more data for our tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markovify\n",
      "  Downloading markovify-0.9.0.tar.gz (27 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (1.18.5)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.25.3)\n",
      "Collecting pytest\n",
      "  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 34.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2021.4.4-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n",
      "\u001b[K     |████████████████████████████████| 722 kB 99.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: seaborn in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (0.11.0)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.0.5-cp36-cp36m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 97.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.3.1)\n",
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 110.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /opt/app-root/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (1.12.1)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 108.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/app-root/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 2)) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/app-root/lib/python3.6/site-packages (from pandas->-r requirements.txt (line 4)) (2020.1)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.10.0-py2.py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 103.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: toml in /opt/app-root/lib/python3.6/site-packages (from pytest->-r requirements.txt (line 5)) (0.10.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/app-root/lib/python3.6/site-packages (from pytest->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.6/site-packages (from pytest->-r requirements.txt (line 5)) (20.4)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/app-root/lib/python3.6/site-packages (from pytest->-r requirements.txt (line 5)) (20.2.0)\n",
      "Collecting pluggy<1.0.0a1,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest->-r requirements.txt (line 5)) (3.4.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 9)) (53.0.0)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 89.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Downloading spacy_legacy-3.0.2-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/app-root/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 9)) (2.24.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/app-root/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 9)) (3.7.4.3)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp36-cp36m-manylinux2014_x86_64.whl (9.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.2 MB 100.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/app-root/lib/python3.6/site-packages (from spacy->-r requirements.txt (line 9)) (2.11.2)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.0-cp36-cp36m-manylinux2014_x86_64.whl (456 kB)\n",
      "\u001b[K     |████████████████████████████████| 456 kB 101.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp36-cp36m-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.2\n",
      "  Downloading thinc-8.0.2-cp36-cp36m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 100.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp36-cp36m-manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 99.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp36-cp36m-manylinux2014_x86_64.whl (20 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp36-cp36m-manylinux2014_x86_64.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 93.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses<1.0,>=0.6 in /opt/app-root/lib/python3.6/site-packages (from pathy>=0.3.5->spacy->-r requirements.txt (line 9)) (0.8)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 97.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 9)) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/app-root/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 9)) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/app-root/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 9)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/app-root/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 9)) (2.10)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in /opt/app-root/lib/python3.6/site-packages (from thinc<8.1.0,>=8.0.2->spacy->-r requirements.txt (line 9)) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /opt/app-root/lib/python3.6/site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.2->spacy->-r requirements.txt (line 9)) (0.14)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /opt/app-root/lib/python3.6/site-packages (from typer<0.4.0,>=0.3.0->spacy->-r requirements.txt (line 9)) (7.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (1.33.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (0.35.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (0.11.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (2.10.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (0.3.3)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (3.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/app-root/lib/python3.6/site-packages (from tensorflow->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (1.22.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/app-root/lib/python3.6/site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (1.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/app-root/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/app-root/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/app-root/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/app-root/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/app-root/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/app-root/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/app-root/lib/python3.6/site-packages (from jinja2->spacy->-r requirements.txt (line 9)) (1.1.1)\n",
      "Building wheels for collected packages: markovify, smart-open\n",
      "  Building wheel for markovify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for markovify: filename=markovify-0.9.0-py3-none-any.whl size=18474 sha256=b80277679589bcd7398842c3cf62a744e8d1bb6841bc8009ece1171841e305f3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3nuki6ss/wheels/32/20/e1/530730d7ef90be154a32f98989aac827474e5f0b65ea5b3468\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107095 sha256=baac5771e7957cbc9ec607b2102a4ca976df8df623c6c959e20397c4eb4da1d3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3nuki6ss/wheels/88/2a/d4/f2e9023989d4d4b3574f268657cb6cd23994665a038803f547\n",
      "Successfully built markovify smart-open\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, unidecode, tqdm, thinc, spacy-legacy, py, pluggy, pathy, iniconfig, tensorflow-hub, spacy, regex, pytest, markovify\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.1 cymem-2.0.5 iniconfig-1.1.1 markovify-0.9.0 murmurhash-1.0.5 pathy-0.4.0 pluggy-0.13.1 preshed-3.0.5 py-1.10.0 pydantic-1.7.3 pytest-6.2.3 regex-2021.4.4 smart-open-3.0.0 spacy-3.0.5 spacy-legacy-3.0.2 srsly-2.4.0 tensorflow-hub-0.11.0 thinc-8.0.2 tqdm-4.60.0 typer-0.3.2 unidecode-1.2.0 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>issue</th>\n",
       "      <th>symptom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my brakes make a noise whenever I try to stop</td>\n",
       "      <td>Brakes</td>\n",
       "      <td>Car makes grinding noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>super frustrating every time I start my car it...</td>\n",
       "      <td>Starter</td>\n",
       "      <td>Car starts then stops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't open the damn door to my car</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I turn the key and nothing happens</td>\n",
       "      <td>Starter</td>\n",
       "      <td>Car doesn't start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Car doesn't always start when it's low on blin...</td>\n",
       "      <td>Starter</td>\n",
       "      <td>Car doesn't start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>my breaks are faulty.</td>\n",
       "      <td>Brakes</td>\n",
       "      <td>Car brakes, but then brakes disengage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>my lights do not work</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>I try to start the engine only to find that th...</td>\n",
       "      <td>Starter</td>\n",
       "      <td>Car doesn't start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>The driver side window auto function does not ...</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Sometimes when I press the brake, the car does...</td>\n",
       "      <td>Brakes</td>\n",
       "      <td>Car doesn't stop in timely manner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              response    issue  \\\n",
       "0        my brakes make a noise whenever I try to stop   Brakes   \n",
       "1    super frustrating every time I start my car it...  Starter   \n",
       "2                 I can't open the damn door to my car    Other   \n",
       "3                   I turn the key and nothing happens  Starter   \n",
       "4    Car doesn't always start when it's low on blin...  Starter   \n",
       "..                                                 ...      ...   \n",
       "104                              my breaks are faulty.   Brakes   \n",
       "105                              my lights do not work    Other   \n",
       "106  I try to start the engine only to find that th...  Starter   \n",
       "107  The driver side window auto function does not ...    Other   \n",
       "108  Sometimes when I press the brake, the car does...   Brakes   \n",
       "\n",
       "                                   symptom  \n",
       "0                 Car makes grinding noise  \n",
       "1                    Car starts then stops  \n",
       "2                                           \n",
       "3                        Car doesn't start  \n",
       "4                        Car doesn't start  \n",
       "..                                     ...  \n",
       "104  Car brakes, but then brakes disengage  \n",
       "105                                         \n",
       "106                      Car doesn't start  \n",
       "107                                         \n",
       "108      Car doesn't stop in timely manner  \n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "100\n",
    "df = pd.read_csv('response.csv') \n",
    "df = df.fillna('')\n",
    "df['response']=df.iloc[:,3]+df.iloc[:,5]+df.iloc[:,6]\n",
    "df['issue'] = df.iloc[:,1]\n",
    "df['symptom'] = df.iloc[:,2] + df.iloc[:,4]\n",
    "subset = df.iloc[:,-3:]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#markovify is a simple, extensible Markov chain generator\n",
    "#Its primary use is for building Markov models of large corpora of text and generating random sentences from that.\n",
    "\n",
    "\n",
    "#Function builds the model according to what issue (e.g. brakes, starter, other) is given\n",
    "def train_markov_type(data, issue):\n",
    "    return markovify.Text(data[data[\"issue\"] == issue].response, retain_original=False, state_size=2)\n",
    "\n",
    "#Function takes one of the 'issue' models and creates a randomly-generated sentence of length up to 200 characters.  Note only creates '1' sentence\n",
    "def make_sentence(model, length=100):\n",
    "    return model.make_short_sentence(length, max_overlap_ratio = .7, max_overlap_total=15)\n",
    "\n",
    "#built models\n",
    "other_model = train_markov_type(subset, \"Other\")\n",
    "brakes_model = train_markov_type(subset, \"Brakes\")\n",
    "starter_model = train_markov_type(subset, \"Starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The warning indicator light is out.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(other_model)  #creates a sentence that should be an example of 'other' issue(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Then I have to press the brakes a bit harder than I normally would.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(brakes_model)  #creates a sentence that should be an example of 'brakes' issue(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have to press the ignition button at least twice before my car but it definitely was not starting.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence(starter_model)   #creates a sentence that should be an example of 'starter' issue(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine these models with relative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a compound model in which the sentences that come out will be 2x as many 'other' than 'brakes' or 'starters'\n",
    "\n",
    "compound_model = markovify.combine([other_model, brakes_model, starter_model], [14, 7, 7])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 20 sentences out of the compound model - copy the text into a spreadsheet and check the count of the issues  (e.g. how many brake issue are there?)\n",
    "\n",
    "for i in range(100):\n",
    "    print(make_sentence(brakes_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def generate_cases(models, weights=None):\n",
    "    if weights is None:\n",
    "        weights = [1] * len(models)\n",
    "    \n",
    "    choices = []\n",
    "    \n",
    "    total_weight = float(sum(weights))\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        choices.append((float(sum(weights[0:i+1])) / total_weight, models[i]))\n",
    "    \n",
    "    def choose_model():\n",
    "        r = numpy.random.uniform()\n",
    "        for (p, m) in choices:\n",
    "            if r <= p:\n",
    "                return m\n",
    "        return choices[-1][1]\n",
    "\n",
    "\n",
    "    def choose_from(c):\n",
    "        idx = math.floor(numpy.random.uniform() * len(c))\n",
    "        return c[idx]\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        yield (make_sentence(choose_model()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compound_model = markovify.combine([other_model, brakes_model, starter_model], [14, 7, 7])  \n",
    "\n",
    "t = generate_cases([other_model, brakes_model, starter_model], [3,4,4])  #actual sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just that odd clicking noise....',\n",
       " \"This is the third one, and I can't get up to 88 MPH\",\n",
       " 'Then I have to brake again.',\n",
       " 'I have some noise when i drive it above 60 mph',\n",
       " 'I feel a bit of rumbling to the car made horrible grinding noises.',\n",
       " 'It sputters for a very long time to start, and if I push the key and nothing happens',\n",
       " \"I think my car if the door won't open.\",\n",
       " 'My car does not start.',\n",
       " \"Car dies when I stop at a light or stop sign and then won't start again.\",\n",
       " 'Maybe the brakes disengage.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "[next(t) for i in range(10)]  #create 100 sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write sentences to CSV file \n",
    "print(list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for similarity (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/54334304/spacy-cant-find-model-en-core-web-sm-on-windows-10-and-python-3-5-3-anacon\n",
    "#in your terminal window, execute the following code, before loading 'en_core_web_sm':\n",
    "\n",
    "#     cd vehicle-claims-processing/\n",
    "#     python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy is a free open-source library for NLP in python\n",
    "#en_core_web_sm is an english pipeline optimized for cpu.  components: tok2vec, tagger, prser, senter, ner, attribure_rulter, lemmantizer\n",
    "#load english tokenizer, tagger, parser and NER\n",
    "#load english tokenizer, tagger, parser and NER\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-30e49a711081>:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  if m < doc.similarity(doc1):\n",
      "<ipython-input-14-30e49a711081>:15: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  m = doc.similarity(doc1)  #m is taking the highest similarity of all the comparisons made  (a[] is a bunch of numbers between 1 and -1)\n",
      "<ipython-input-14-30e49a711081>:14: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  if m < doc.similarity(doc1):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity: 0.8125149986037026\n",
      "[0.8393195439119241, 0.8451555708947686, 0.8280475410952531, 0.671093154854383, 1.0, 0.876784986485434, 0.6619173085767404, 1.0, 1.0, 0.857301763395154, 0.548411552826165, 0.9299268821306551, 0.7698688657444562, 1.0, 0.7825631570988464, 0.6417640723577596, 0.5582718161907415, 0.3136168095685487, 0.7328827513175139, 1.0, 0.7341716024427714, 1.0, 1.0, 0.7971669406663372, 0.671556830276128, 0.5677476852512697, 0.6076775201447694, 1.0, 0.5644226629695164, 0.7077358889264597, 0.8518026948057146, 1.0, 0.6064920154782988, 0.7739907002074002, 1.0, 0.7041479208744454, 0.9025749334899409, 1.0, 0.5757656850495764, 0.8043378292358959, 1.0, 0.8004870946977029, 1.0, 0.7971669406663372, 0.7852978743723277, 0.8206557446158871, 0.8107326633893506, 0.7128111958192636, 0.8146783402506725, 0.7151699003077256, 0.8021649162574365, 0.7494423615817143, 1.0, 1.0, 0.5707095176683428, 0.638484595237507, 0.8515417569063928, 0.8419749711125252, 0.7534710753140295, 1.0, 1.0, 0.8839301168029375, 0.9617983293368074, 0.6701604401467355, 1.0, 0.7213332993365416, 0.7733844393526256, 1.0, 1.0, 0.8940094884046713, 1.0, 0.7761612711024339, 0.8256677476003313, 1.0, 0.6688053078243571, 0.5750886215355827, 1.0, 1.0, 0.6277181723330252, 1.0, 0.9316488925472066, 0.8461350075911327, 0.7909137606285489, 0.753279249675599, 0.7031731512943571, 0.7605101045384973, 0.7194638137904598, 0.6639891418280871, 0.893497517627217, 0.8002350705989173, 0.6766291231204512, 0.7059881010531499, 0.8475043178565862, 0.7857739365949139, 0.8285985349769188, 0.70202533847362, 0.7909137606285489, 0.7632864516088832, 0.9078390543076835, 0.8107326633893506]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f5e40ead4f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load english tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load('en_core_web_sm')  #the nlp is going to tokenize the lists dt_b, dt_a\n",
    "\n",
    "dt_b = subset[\"response\"]  #109 responses (from our google form) in our response.csv\n",
    "dt_a = [next(t) for i in range(100)]  #created sentences from 3 models that were combined.  Remember the 3 models were (created) based on the the reponse.csv issues (categories)\n",
    "\n",
    "import numpy as np\n",
    "a = []\n",
    "for sentence in dt_a:\n",
    "    doc = nlp(sentence)\n",
    "    m = 0\n",
    "    for sentence1 in dt_b:\n",
    "        doc1 = nlp(sentence1)\n",
    "        if m < doc.similarity(doc1):\n",
    "            m = doc.similarity(doc1)  #m is taking the highest similarity of all the comparisons made  (a[] is a bunch of numbers between 1 and -1)\n",
    "    a.append(m)\n",
    "        \n",
    "print(\"Mean similarity: \" + str(np.array(a).mean()))\n",
    "print(a)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.displot(a)\n",
    "\n",
    "#plotting generated sentences vs google form sentences.  For each google form sentence, what was the most similiar in the list of generated sentences.\n",
    "#have a fairly normal distributation which demonstrates that our nlp generation isn't bad :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "def timing(c):\n",
    "    for _ in range(c):\n",
    "        next(t)\n",
    "\n",
    "cProfile.run('timing(2000)', 'generatestats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('generatestats')\n",
    "p.strip_dirs().sort_stats(-1).print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
